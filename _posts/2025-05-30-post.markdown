---
layout: post
title: Logit (2)：最適応答とその摂動化
running_head: Logit (2)
categories: RUMs
misc: 
---

## 混合最適応答

ここで，改めて決定論的なアプローチを考えてみよう．引き続き，選択肢 $a \in A$ と対応する利得 $v = (v_a)_{a\in A}$ が与えられているとする．意思決定者の問題は，以下の線形最適化問題を解くことによって利得を最大化する混合戦略を決定することだとしよう：

$$
\max_{y \in \Delta} \quad \langle v, y \rangle
$$

ここで，$\Delta \equiv  \\{ y \ge \mathbf{0} \mid \sum_{a \in A} y_a = 1 \\}$ は確率単体 (probability simplex) を表し，$\langle v, y \rangle = \sum v_a y_a $ は $v$ と $y$ の内積を意味する．

この問題の解 $y^\star$ は，次の条件を満たさなければならない：

$$
y_a^\star > 0 \Rightarrow a \in \operatorname{br}(v),
$$

ここで，

$$
\operatorname{br}(v) \equiv \arg\max_{b \in A} \\{v_b\\}
$$ 

は，利得ベクトル $v$ が与えられたとき利得を最大化する選択肢の集合である．

このような $y^\star$ は凸集合を形成するが，$\operatorname{br}(v)$ の要素は複数の選択肢が利得を最大化する場合は唯一ではない．このため，$y^\star$ の一意性は常に保証されるわけではない（cf. 線形最適化問題の解の一意性）．

上述の最適化問題に対応する **双対** (dual) 問題は，次のように与えられる：

$$
\min_{\lambda} 
\quad \lambda 
\qquad \text{s.t.} \quad 
\lambda \ge v_a \quad \forall a \in A．
$$

この問題は，DM が達成可能な利得に対する最良の上界（=最小の上界）を得ることを目的としている．明らかに，この問題の解および最適値は $\lambda^\star = \max_{a \in A} v_a$ であり，これは当初の最適化問題の最適値と一致する（=線形最適化における **強双対性** (strong duality)）．



<div class="back-of-envelope">
<div class="boe-title">最適応答の双対問題の導出</div>
<div class="boe-conents">
まず，$\lambda$を制約 $\sum_{a\in A} y_a = 1$ に対する Lagrange 乗数としよう．Lagrange 関数は
$$
\begin{aligned}
    L(y, \lambda) 
    \equiv \langle v, y \rangle - \lambda \left(\langle \boldsymbol 1, y \rangle - 1\right)
    = - \langle \lambda\boldsymbol 1 - v, y \rangle +\lambda
\end{aligned}
$$
ただし $y \ge\boldsymbol 0$．
Lagrange 双対問題は以下の目的関数を最小化する問題であるから，上述の双対問題を得る：
\begin{align}
    \omega(\lambda) 
    = \sup_{y\ge 0} L(y,\lambda) 
    = \sup_{y\ge 0} \lambda -\langle\lambda\boldsymbol 1 - v, y \rangle 
    = 
    \begin{cases}
        \lambda & \text{if } \lambda \ge v_a \quad \forall a \in A,\\ 
        \infty & \text{otherwise}. 
    \end{cases} 
\end{align}
</div>
</div>

##  摂動付き最適化問題

先に見たように，決定論的アプローチでは，DMの選択に関して一意的な予測が得られない．最適化理論の観点から見ると，これは最適応答が線形最適化問題であることに起因している．こうした場合には，解の一意性を保証するために **正則化項** (regularization term) を加えてみるのが自然な発想の一つとなる．

DM の最適応答の問題が次のように変更されたと仮定する：

$$
\max_{y \in \Delta} \ \langle v, y \rangle - H(y)
$$

関数 $H:\text{int}(\Delta) \to \mathbb{R}$ は，狭義凸 (strictly convex) であり，$y$ が $\Delta$ の境界に近づくにつれて勾配が際限なく急になる（発散する）と仮定する．このとき，目的関数は狭義凹であり，かつ実行可能領域 $\Delta$ が凸かつ有界で閉（= 有限次元なのでコンパクト性と等価）であるため，この修正された問題は一意な解を持つ．

代表的ケースとして，$H$ が **負のエントロピー** (negative entropy) であると仮定した場合を考えよう

$$
H(y) = \eta \sum_{a \in A} y_a \log y_a，
$$

ただし，$0 \log 0 \equiv 0$ と定義する．明らかに，$\eta \to 0$ のとき最初の問題に収束する．

最適解 $y^\star$ は，ロジット選択則と一致する：

$$
y_a^\star = p_a = \frac{\exp(\eta^{-1} v_a)}{\sum_{b\in A} \exp(\eta^{-1} v_b)}．
$$

また，正則化された問題の最適値は次のように表される：

$$
\lambda(v) 
\equiv \langle v, y^\star \rangle - \eta \langle y^\star, \log y^\star \rangle  
= \eta \log \sum_{a \in A} \exp(\eta^{-1} v_a)．
$$

この最適値は，ロジットモデルにおける期待最大効用と一致する．更に，

$$
\frac{\partial \lambda(v)}{\partial v_a} = \frac{\exp(\eta^{-1} v_a)}{\sum_{b\in A} \exp(\eta^{-1} v_b)} = p_a．
$$

すなわち，関数 $\lambda(v)$ は利得ベクトル $v$ に関する滑らかな関数であり，その勾配はロジット確率に一致する．最適値関数 $\lambda(v)$ は，定義より関数 $H$ の**凸共役** (convex conjugate) あるいは Legendre変換に他ならず，この事実が $p_a$ の $\lambda(v)$ の勾配としての表現にもつながっている．実際，この関係は凸最適化において一般的に現れるものであり，ロジットモデル以外のモデルでも最適値関数の勾配が選択確率として表現されることがある．

正則化付き問題の **ラグランジュ双対問題** は次のように表される：

$$
\min_{\lambda} \ \lambda 
\quad \text{s.t.} \quad 
\lambda = \eta \log \sum_{a \in A} \exp(\eta^{-1} v_a)
$$

この双対問題の解が主問題の最適値と一致するのは明らかである（**凸最適化における強双対性**）．また，

$$
    \lim_{\eta \to 0} \lambda(v) = \max_{a \in A} v_a. 
$$

となり，非正則化ケースの線形問題における双対問題とも対応する．



<div class="back-of-envelope">
<div class="boe-title">摂動問題の最適解と双対問題の導出</div>
<div class="boe-conents">
Lagrange 関数は $L(y, \lambda) \equiv - \langle v, y \rangle + \lambda \left(\langle\boldsymbol 1, y \rangle - 1\right) + H(y)$. 最適性条件は
$$
\begin{aligned}
    & 
    y_a \dfrac{\partial L(y,\lambda)}{\partial y_a} = 0, y_a \ge 0, \dfrac{\partial L(y,\lambda)}{\partial y_a} =  - v_a + \lambda + \eta \log y_a + \eta\ge0, \label{eq:PBR-opt}\\
    & \dfrac{\partial L(y,\lambda)}{\partial \lambda} = \sum_a y_a - 1 = 0. 
\end{aligned}
$$
ここで $y_a \to 0$ のとき $\frac{\partial L(y,\lambda)}{\partial y_a} \to -\infty$ であるから, $y_a = 0$ は解として不適．
従って $y_a > 0$．$\frac{\partial L(y,\lambda)}{\partial y_a} = 0$，すなわち $y_a = \exp\left(\eta^{-1} \left(v_a - \lambda \right) - 1\right)$. 
更に，制約 $\sum_a y_a = 1$ より，

$$
\begin{aligned}
    & \lambda^\star = \eta \log \sum_{a\in A} \exp(\eta^{-1} v_a) - \eta. 
\end{aligned}
$$

であり，これを用いると既にみたロジット選択則を得る．また，$\sup_{y \ge 0} L(y,\lambda) = \lambda^\star + \eta$ であり，実際には既に $\lambda$ について解けた形で双対問題が得られる．Lagrange 乗数 $\lambda^\star$ が定数分だけ確率的選択の文脈の MEU とずれるのが気になる場合は $H(y)$ の定義を微修正すればよいが，選択確率と最適値には影響しない．
</div>
</div>

さて，$\eta \to 0$ のとき，$y_a > 0$ となるのは $a \in \operatorname{br}(v)$ の場合に限られ，$a \notin \operatorname{br}(v)$ のときは $y_a \to 0$ となる．これは正則化なしのケースと整合的である．実際，

$$
\begin{aligned}
y_a 
& = \frac{1}{\sum_{b\in A} \exp(\eta^{-1} (v_b - v_a ))}\\
& = \frac{1}{|\operatorname{br}(v)| + \sum_{b\notin \operatorname{br}(v)} \exp(\eta^{-1} (v_b - v_a ))}．
\end{aligned}
$$

であるから，もし $a \notin \operatorname{br}(v)$ であれば，
ある $b \in A$ 対して $v_b > v_a$ となる．
このとき，$\eta \to 0$ で分母が無限大に発散するから，$y_a \to 0$ である．
ただし，$a \in \operatorname{br}(v)$ の場合 $y_a \to 1 / |\operatorname{br}(v)|$ となる．これは正則化なしのケースとはわずかに異なる．通常の混合戦略による最適反応は一意でない可能性があるためである．


異なる凸関数 $H$ を用いることで，異なる選択ルールが導かれる．現実に使用されるすべての ARUM は，このような **摂動最適化問題** によって表現されるが，すべての摂動最適化問題の解に対応する ARUM が存在するとは限らない [(Fosgerau et al., 2020)](https://onlinelibrary.wiley.com/doi/10.1111/iere.12469)．日本語のサーベイとしては [福田・城間 (2023)](https://www.jstage.jst.go.jp/article/jscejipm/78/5/78_I_1/_article/-char/ja/) を参照のこと．